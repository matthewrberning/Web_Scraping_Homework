{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matthew Berning\n",
    "# import dependancies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup # as bs\n",
    "import requests\n",
    "from requests import get\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "mars_news_url = 'https://mars.nasa.gov/news/'\n",
    "#  Retrieve page with the requests module\n",
    "response = requests.get(mars_news_url)\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup_level0 = BeautifulSoup(response.text, 'lxml')\n",
    "#test\n",
    "# print(soup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NASA's InSight Places First Instrument on Mars\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get all article titles (that are able to be scraped)\n",
    "article_titles = soup_level0.find_all('div', class_='content_title')\n",
    "# print(article_titles)\n",
    "\n",
    "#retrieve just the first article's title \n",
    "#(there is a problem with the BS codebase, it is somehow only scraping the infromation from the scrolling carosel on the very bottom of the page)\n",
    "\n",
    "first_article = soup_level0.find('div', class_='content_title').get_text()\n",
    "print(first_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In deploying its first instrument onto the surface of Mars, the lander completes a major mission milestone.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get article description\n",
    "first_article_description = soup_level0.find('div', class_='rollover_description_inner').get_text()\n",
    "print(first_article_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA14400_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "#url for featured image to be scraped\n",
    "space_images_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# create a new chrome session\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(space_images_url)\n",
    "\n",
    "#use selenium to click button 'full image'\n",
    "python_button = driver.find_element_by_id('full_image') \n",
    "python_button.click() #click  link\n",
    "\n",
    "#once 'full image' is opened click 'more info' button to get to ACTUAL page with the full res image\n",
    "python_button = driver.find_element_by_partial_link_text('more info')\n",
    "python_button.click() #click link\n",
    "\n",
    "#on the new page use beautifulsoup to get page source\n",
    "soup_level1=BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "#test the soup to find full resloution image\n",
    "# soup_level1.body.find_all('img', class_ ='main_image')\n",
    "\n",
    "#pull out image 'src' by class and 'img' tag\n",
    "img_find_src = [i['src'] for i in soup_level1.findAll('img', {'class': 'main_image'})]\n",
    "# from STACKOVERFLOW: https://stackoverflow.com/questions/8289957/python-2-7-beautiful-soup-img-src-extract \n",
    "\n",
    "#cast soup.find to string\n",
    "img_str = str(img_find_src)\n",
    "#need to remove brackets and appostrophies from string generated by above\n",
    "whitelist = string.ascii_letters + string.digits + '/' + '_' + '.'\n",
    "img_url_end = ''\n",
    "for char in img_str:\n",
    "    if char in whitelist:\n",
    "        img_url_end += char\n",
    "    else:\n",
    "        img_url_end += ''\n",
    "#from STACKOVERFLOW: https://stackoverflow.com/questions/875968/how-to-remove-symbols-from-a-string-with-python        \n",
    "       \n",
    "img_url_start = 'https://www.jpl.nasa.gov' #begining of url\n",
    "featured_img_url = (img_url_start + img_url_end) #FEATURED IMAGE FULL RESOLOUTION URL\n",
    "print(featured_img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t\tThe Case of the Warped Galactic Ring\t\t\t  \n",
      "------------\n",
      "paragraph No.1:\n",
      "------------\n",
      "\n",
      "------------\n",
      "paragraph No.2:\n",
      "------------\n",
      "\n",
      "------------\n",
      "paragraph No.3:\n",
      "------------\n",
      "In a strange twist of science, astronomers using the Herschel Space Observatory have discovered that a suspected ring at the center of our galaxy is warped for reasons they cannot explain. This image from Herschel, an infrared European Space Agency-led mission with important NASA contributions, reveals the ring with greater clarity than ever before. It can be seen as the yellow loop that appears to have two lobes (Figure 1). In fact, the ring, which is a collection of very dense and cold gas and dust, is twisted so that part of it rises above and below the plane of our Milky Way galaxy. \n",
      "------------\n",
      "paragraph No.4:\n",
      "------------\n",
      "Previous observations had revealed portions of the ring. Herschel sees long-wavelength infrared light, which can penetrate through the murky region at the center of our galaxy, allowing Herschel to get a more complete view.\n",
      "------------\n",
      "paragraph No.5:\n",
      "------------\n",
      "Astronomers aren't sure how rings like this form in galaxies but some theories suggest they arise out of gravitational disturbances with neighboring galaxies. New stars are thought to be forming in the dense gas making up the ring.\n",
      "------------\n",
      "paragraph No.6:\n",
      "------------\n",
      "The ring stretches across more than 600 light-years of space, and is about 15 Kelvin (minus 433 degrees Fahrenheit). The warmest material in this picture is blue, and the coldest is red. \n",
      "------------\n",
      "paragraph No.7:\n",
      "------------\n",
      "The image was taken using two of Herschel's instruments -- the photodetector array camera and spectrometer (70-micron-light is coded blue; 160-micron light is coded green) and the spectral and photometric imaging receiver (350-micron light is red).\t\t\t  \n"
     ]
    }
   ],
   "source": [
    "#the 'featured image' from the home work link is not always mars, even though it should be, \n",
    "#so it will just be a featured space image that will be put at the bottom of the finished webpage along with the other mars stuff\n",
    "\n",
    "#capture image title\n",
    "featured_image_title = soup_level1.find('h1', class_=\"article_title\").text\n",
    "#test\n",
    "# print(featured_image_title)\n",
    "\n",
    "#capture using beautiful soup all paragraph elements \n",
    "paragraphs = soup_level1.find_all('p')\n",
    "\n",
    "#create empty list to contain p elements\n",
    "paragraph_list = []\n",
    "\n",
    "#iterate through retrieved paragraphs and conditinally append to paragraph list\n",
    "for paragraph in paragraphs:\n",
    "    p = [] #make empty list to contain text from each paragraph element individually\n",
    "    p.append(paragraph.text)\n",
    "    if any(\"Mission:\" in s for s in p): #from STACKOVERFLOW: https://stackoverflow.com/questions/4843158/check-if-a-python-list-item-contains-a-string-inside-another-string\n",
    "        break #end the loop when infromation from the 'image details' section of p elements is entered\n",
    "    else:\n",
    "        paragraph_list.append(paragraph) #append each paragraph to the paragraph list\n",
    "#test\n",
    "print(featured_image_title)\n",
    "\n",
    "j = 1\n",
    "\n",
    "for i in range(len(paragraph_list)):\n",
    "    print(\"------------\")\n",
    "    print(\"paragraph No.\" + str(j)+\":\")\n",
    "    print(\"------------\")\n",
    "    print(paragraph_list[i].text)\n",
    "    j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol 2298 (2019-01-23), high -9C/15F, low -71C/-95F, pressure at 8.17 hPa, daylight 06:46-18:55pic.twitter.com/HNaq1Rjsoq\n"
     ]
    }
   ],
   "source": [
    "# URL to get mars weather from twitter\n",
    "mars_weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "#  Retrieve page with the requests module\n",
    "response = requests.get(mars_weather_url)\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup_level2 = BeautifulSoup(response.text, 'lxml')\n",
    " \n",
    "#make empty list for weather tweets\n",
    "weather_tweets = []\n",
    "\n",
    "#iterate through soup and get tweet text\n",
    "for li in soup_level2.find_all(\"li\", {\"data-item-type\": \"tweet\"}):\n",
    "    #make empty lists for all available tweets on page\n",
    "    all_tweets = []\n",
    "    text_p = li.find(\"p\", class_=\"tweet-text\")\n",
    "    if text_p is not None:\n",
    "        all_tweets.append(text_p.get_text()) #from STACKOVERFLOW: https://stackoverflow.com/questions/51653786/how-to-get-all-tweets-from-a-public-account-by-beautifulsoup\n",
    "        #iterate through list of tweets and keep only ones that start with 'Sol'\n",
    "        for i in all_tweets: \n",
    "            t = []\n",
    "            t.append(i)\n",
    "            if any(\"Sol\" in s for s in t):\n",
    "                weather_tweets.append(i)\n",
    "\n",
    "#assign just the first *most current* one to variable \n",
    "current_mars_weather = str(weather_tweets[0])\n",
    "\n",
    "print(current_mars_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Info Type:</th>\\n      <th>Data:</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL for mars geophysical facts\n",
    "url = 'https://space-facts.com/mars/'\n",
    "#read html with pandas and push into list\n",
    "get_table = pd.read_html(url)\n",
    "#test\n",
    "# get_table\n",
    "#build dataframe from table using index, because apparently you have to\n",
    "df = get_table[0]\n",
    "#rename columns \n",
    "df.columns = ['Info Type:', 'Data:']\n",
    "#test\n",
    "# df\n",
    "#use pandas to turn table into an html string\n",
    "mars_facts_html_table = df.to_html()\n",
    "#test\n",
    "mars_facts_html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MARS HEMISPHERES PLACE HOLDER\n",
    "#UNABLE TO SCRAPE BECAUSE THE GOVERNMENT IS SHUT\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#END PLACE HOLDER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
